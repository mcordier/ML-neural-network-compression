{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import eig\n",
    "import pandas as pd\n",
    "import scipy.linalg as la\n",
    "from scipy.spatial.distance import pdist, squareform, cdist\n",
    "from sklearn.metrics.pairwise import polynomial_kernel, cosine_similarity\n",
    "from sklearn.metrics.pairwise import sigmoid_kernel, linear_kernel\n",
    "from sklearn.metrics.pairwise import laplacian_kernel\n",
    "from scipy.optimize import minimize\n",
    "import pdb\n",
    "import tensorflow as tf\n",
    "from kdpp import kDPP\n",
    "np.random.seed(1) #Fix the seed\n",
    "print (\"Packages loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Introduction to DPP : a very simple example\n",
    "We would like to test our kdpp class for a very simple example in two dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Kernel\n",
    "def kernel_se(_X1,_X2,_hyp={'gain':1,'len':1,'noise':1e-8}):\n",
    "    hyp_gain = float(_hyp['gain'])**2\n",
    "    hyp_len  = 1/float(_hyp['len'])\n",
    "    pairwise_dists = cdist(_X1,_X2,'euclidean')\n",
    "    K = hyp_gain*np.exp(-pairwise_dists ** 2 / (hyp_len**2))\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data\n",
    "n = 200\n",
    "k = 10\n",
    "x = np.random.rand(n,2)\n",
    "\n",
    "# K-DPP and randomm sample \n",
    "kdpp = kDPP(x, kernel_se)\n",
    "kdpp_out,_ = kdpp.sample(k = k)\n",
    "rand_out = x[np.random.permutation(n)[:k],:]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(x[:,0],x[:,1],'k.')\n",
    "hr, = plt.plot(rand_out[:,0],rand_out[:,1],marker='o',mec='blue',mfc='None',markersize=15,linestyle='None',mew=4)\n",
    "hk, = plt.plot(kdpp_out[:,0],kdpp_out[:,1],marker='o',mec='red',mfc='None',markersize=15,linestyle='None',mew=4)\n",
    "plt.xlim(0.0,1.0); plt.ylim(0.0,1.0)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.legend([hr,hk],['Random sample','K-DPP'],fontsize=15,loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Kernels definition\n",
    "We want to compare the efficiency of the algorithm with different kernels. We define them here (or recall the function call for sklearn kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angular(X1, X2, *args):\n",
    "    def Gort(G):\n",
    "        Q, R = np.linalg.qr(G)\n",
    "        return Q\n",
    "    Gort = Gort(np.random.normal(size=(len(X1),len(X1))))\n",
    "    phi1 = 1/np.sqrt(len(X1))*np.sign(np.dot(Gort,X1))\n",
    "    phi2 = 1/np.sqrt(len(X2))*np.sign(np.dot(Gort,X2))\n",
    "    return np.dot(phi1,phi2.T)\n",
    "\n",
    "# sklearn kernels : cosine_similarity(X1,X2), polynomial_kernel(X1,X2), \n",
    "# laplacian_kernel(X1,X2), sigmoid_kernel(X1,X2), angular(X1,X2), linear_kernel(X1,X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Building and training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-5c81c5f4c9da>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(data=mnist, learning_rate = 0.05, epochs = 30,\n",
    "                batch_size = 100, hidden1 = 500, hidden2 = 500):\n",
    "    '''\n",
    "    Creates a 2 layers fully connected neural network\n",
    "    '''\n",
    "    # declare the training data placeholders\n",
    "    # input x - for 28 x 28 pixels = 784\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    # now declare the output data placeholder - 10 digits\n",
    "    y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    # now declare the weights connecting the input to the hidden layer\n",
    "    W1 = tf.Variable(tf.random_normal([784, hidden1], stddev=0.03), name='W1')\n",
    "    b1 = tf.Variable(tf.random_normal([hidden1]), name='b1')\n",
    "    # the weights connecting the hidden layer to the other hidden layer\n",
    "    W2 = tf.Variable(tf.random_normal([hidden1, hidden2], stddev=0.03), name='W2')\n",
    "    b2 = tf.Variable(tf.random_normal([hidden2]), name='b2')\n",
    "    # and the weights connecting the hidden layer to the output layer\n",
    "    W3 = tf.Variable(tf.random_normal([hidden2, 10], stddev=0.03), name='W2')\n",
    "    b3 = tf.Variable(tf.random_normal([10]), name='b2')\n",
    "\n",
    "    # calculate the output of the hidden layers\n",
    "    hidden_out_1 = tf.add(tf.matmul(x, W1), b1)\n",
    "    hidden_out_1 = tf.nn.relu(hidden_out_1)\n",
    "    hidden_out_2 = tf.nn.relu(tf.add(tf.matmul(hidden_out_1, W2), b2))\n",
    "    # now calculate the hidden layer output - in this case, let's use a softmax activated\n",
    "    # output layer\n",
    "    y_ = tf.nn.softmax(tf.add(tf.matmul(hidden_out_2, W3), b3))\n",
    "\n",
    "\n",
    "    #Compute cross entropy\n",
    "    y_clipped = tf.clip_by_value(y_, 1e-10, 0.9999999) # Being sure we don't have ln(0)\n",
    "    cross_entropy = -tf.reduce_mean(tf.reduce_sum(y * tf.log(y_clipped)\n",
    "                             + (1 - y) * tf.log(1 - y_clipped), axis=1))\n",
    "\n",
    "    # add an optimiser\n",
    "    optimiser = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "\n",
    "    # finally setup the initialisation operator\n",
    "    init_op = tf.global_variables_initializer()\n",
    "\n",
    "    # define an accuracy assessment operation\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # start the session\n",
    "    with tf.Session() as sess:\n",
    "        # initialise the variables\n",
    "        sess.run(init_op)\n",
    "        total_batch = int(len(data.train.labels) / batch_size)\n",
    "        for epoch in range(epochs):\n",
    "            avg_cost = 0\n",
    "            for i in range(total_batch):\n",
    "                batch_x, batch_y = data.train.next_batch(batch_size=batch_size)\n",
    "                _, c = sess.run([optimiser, cross_entropy], \n",
    "                             feed_dict={x: batch_x, y: batch_y})\n",
    "                avg_cost += c / total_batch\n",
    "            print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(avg_cost))\n",
    "        print(sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "        Weights1 = sess.run(W1)\n",
    "        Weights2 = sess.run(W2)\n",
    "        Weights3 = sess.run(W3)\n",
    "        bias1 = sess.run(b1)\n",
    "        bias2 = sess.run(b2)\n",
    "        bias3 = sess.run(b3)\n",
    "    parameters = [(Weights1, bias1), (Weights2, bias2), (Weights3, bias3)]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Neural Network compression procedure\n",
    "We start by giving the rebuild_act_labels function which compute the activation vector of each neurons of a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_act_labels_mean(Weights1,  Weights2, bias1, bias2):\n",
    "    #Rebuild the activations:\n",
    "    act_layer1 = np.zeros((10,len(bias1)))\n",
    "    act_layer2 = np.zeros((10,len(bias2)))\n",
    "    \n",
    "    for i in range(len(mnist.train.images)):\n",
    "        act_layer1[np.argmax(mnist.train.labels[i]),:] += np.maximum(\n",
    "            0,(np.dot(Weights1.T, mnist.train.images[i]) + bias1))\n",
    "        act_layer2[np.argmax(mnist.train.labels[i]),:] += np.maximum(\n",
    "            0,(np.dot(Weights2.T, act_layer1[np.argmax(mnist.train.labels[i]),:] ) + bias2))\n",
    "        \n",
    "    for i in range(10):\n",
    "        count = np.sum(i == np.argmax(mnist.train.labels, axis = 1))\n",
    "        act_layer1[i,:] /= count\n",
    "        act_layer2[i,:] /= count\n",
    "        \n",
    "    return act_layer1, act_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Compute softmax values for each sets of scores in x.\n",
    "    \n",
    "    Rows are scores for each class. \n",
    "    Columns are predictions (samples).\n",
    "    \"\"\"\n",
    "    scoreMatExp = np.exp(np.asarray(x))\n",
    "    return scoreMatExp / scoreMatExp.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_act_labels_im(Weights1, Weights2, Weights3, bias1, bias2, bias3, idx_f):\n",
    "    #Rebuild the activations:\n",
    "    act_layer1 = np.zeros((len(idx_f),len(bias1)))\n",
    "    act_layer2 = np.zeros((len(idx_f),len(bias2)))\n",
    "    act_layer3 = np.zeros((len(idx_f),len(bias3)))\n",
    "    \n",
    "    for i in range(len(idx_f)):\n",
    "        act_layer1[i,:] = np.maximum(\n",
    "            0,(np.dot(Weights1.T, mnist.train.images[idx_f[i]]) + bias1))\n",
    "        act_layer2[i,:] = np.maximum(\n",
    "            0,(np.dot(Weights2.T, act_layer1[i, :]) + bias2))\n",
    "        act_layer3[i,:] = softmax(\n",
    "            np.dot(Weights3.T, act_layer2[i, :]) + bias3)\n",
    "    return act_layer1, act_layer2, act_layer3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the neurons we keep and the one we drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_neurons(idx, layer, parameters):\n",
    "    '''\n",
    "    idx : (list) : list of the chosen index with kdpp\n",
    "    layer (int) : layer considered\n",
    "    parameters (ndarray,ndarray) : weights and bias of the considered layer'''\n",
    "    #Split weights between the ones we keep and the ones we drop\n",
    "    #Prune for the first layer\n",
    "    weights_prev, bias_prev = parameters[layer - 1]\n",
    "    weights_cur, bias_cur = parameters[layer] #weights of the layer\n",
    "\n",
    "    new_weights_prev = weights_prev[:, idx]\n",
    "    drop_idx = list()\n",
    "    for i in np.arange(weights_cur.shape[0]):\n",
    "        if i not in idx:\n",
    "            drop_idx += [i]\n",
    "    new_weights_cur = weights_cur[idx]\n",
    "    new_bias_prev = bias_prev[idx]\n",
    "    drop_weights = weights_cur[drop_idx]\n",
    "\n",
    "    new_parameters = parameters.copy()\n",
    "    new_parameters[layer - 1] = (new_weights_prev, new_bias_prev)\n",
    "    new_parameters[layer] = (new_weights_cur, bias_cur)\n",
    "        \n",
    "    \n",
    "    return new_parameters, drop_idx, drop_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reweighting procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweight(layer, activations, new_parameters, idx, drop_idx, drop_weights):\n",
    "    '''\n",
    "    idx : (list) : list of the chosen index with kdpp\n",
    "    activations (list) : activations vectors for each layers\n",
    "    layer (int) : layer considered\n",
    "    parameters (ndarray,ndarray) : weights and bias of the considered layer\n",
    "    idx (list) : chosen index with kdpp\n",
    "    drop_idx (list) : index of the non-chosen neurons'''\n",
    "    \n",
    "    act_idx = activations[0]\n",
    "    act_layer = activations[layer]\n",
    "    act_layer_aft = activations[layer + 1]\n",
    "    weights_cur, bias_cur = new_parameters[layer]\n",
    "    alpha = np.empty((len(act_idx),len(drop_idx) ))\n",
    "    drop_acti = act_layer[drop_idx]\n",
    "    \n",
    "    def proj1(alpha, ind, v1 = drop_acti, v2 = act_idx):\n",
    "        return np.linalg.norm(v1[ind] - np.dot(alpha, v2))\n",
    "    \n",
    "    alpha_results = []\n",
    "    for i in range(len(drop_idx)):\n",
    "        if i%50 == 0:\n",
    "            print(\"step\", i)\n",
    "        alpha_results += [minimize(proj1, np.random.random(len(act_idx)), (i))]\n",
    "    \n",
    "    for i in range(len(drop_idx)):\n",
    "        alpha[:, i] = alpha_results[i]['x']\n",
    "\n",
    "    #Now fuse the dropped weights within the kept ones   \n",
    "    new_weights_cur = weights_cur.copy()\n",
    "    for i in range(weights_cur.shape[0]):\n",
    "        add_weights = np.dot(alpha, drop_weights)\n",
    "        for j in range(weights_cur.shape[1]):\n",
    "            new_weights_cur[i][j] += add_weights[i][j]\n",
    "            \n",
    "    new_parameters = new_parameters.copy()\n",
    "    new_parameters[layer] = (new_weights_cur, bias_cur)\n",
    "    \n",
    "    return new_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Experiments\n",
    "### a) Find the best kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch: 1 cost = 1.084\n",
      "Epoch: 2 cost = 0.481\n",
      "Epoch: 3 cost = 0.377\n",
      "Epoch: 4 cost = 0.306\n",
      "Epoch: 5 cost = 0.255\n",
      "Epoch: 6 cost = 0.219\n",
      "Epoch: 7 cost = 0.188\n",
      "Epoch: 8 cost = 0.165\n",
      "Epoch: 9 cost = 0.144\n",
      "Epoch: 10 cost = 0.128\n",
      "Epoch: 11 cost = 0.115\n",
      "Epoch: 12 cost = 0.102\n",
      "Epoch: 13 cost = 0.092\n",
      "Epoch: 14 cost = 0.084\n",
      "Epoch: 15 cost = 0.075\n",
      "Epoch: 16 cost = 0.068\n",
      "Epoch: 17 cost = 0.060\n",
      "Epoch: 18 cost = 0.055\n",
      "Epoch: 19 cost = 0.050\n",
      "Epoch: 20 cost = 0.044\n",
      "Epoch: 21 cost = 0.041\n",
      "Epoch: 22 cost = 0.035\n",
      "Epoch: 23 cost = 0.032\n",
      "Epoch: 24 cost = 0.029\n",
      "Epoch: 25 cost = 0.026\n",
      "Epoch: 26 cost = 0.024\n",
      "Epoch: 27 cost = 0.021\n",
      "Epoch: 28 cost = 0.019\n",
      "Epoch: 29 cost = 0.017\n",
      "Epoch: 30 cost = 0.015\n",
      "0.9802\n"
     ]
    }
   ],
   "source": [
    "parameters = network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    }
   ],
   "source": [
    "Weights1, bias1 = parameters[0]\n",
    "Weights2, bias2 = parameters[1]\n",
    "Weights3, bias3 = parameters[2]\n",
    "\n",
    "k_f = 1100\n",
    "kddpf = kDPP(mnist.train.images[:3300], kernel_se)\n",
    "act_f, idx_f = kddpf.sample(k_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 1\n",
    "k_1 = 250\n",
    "act_layer1, act_layer2, act_layer3 = rebuild_act_labels_im(Weights1,  Weights2, Weights3, bias1, bias2, bias3, idx_f)\n",
    "kdpp1 = kDPP(act_layer1.T, kernel_se)\n",
    "act_idx1, idx1 = kdpp1.sample(k_1)\n",
    "new_parameters1, drop_idx, drop_weights = prune_neurons(idx1, layer, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 1100)\n",
      "(250, 1100)\n",
      "(250, 250)\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n"
     ]
    }
   ],
   "source": [
    "activations = np.array([act_idx1, act_layer1.T, act_layer2.T, act_layer3.T])\n",
    "new_parameters1 = reweight(layer, activations, new_parameters1, idx1, drop_idx, drop_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 2\n",
    "k_2 = 250\n",
    "kdpp2 = kDPP(act_layer2.T, kernel_se)\n",
    "act_idx2, idx2 = kdpp2.sample(k_2)\n",
    "new_parameters2, drop_idx, drop_weights = prune_neurons(idx2, layer, new_parameters1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n"
     ]
    }
   ],
   "source": [
    "activations = np.array([act_idx2, act_layer1.T, act_layer2.T, act_layer3.T])\n",
    "new_parameters2 = reweight(layer, activations, new_parameters2, idx2, drop_idx, drop_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_nets(new_parameters, learning_rate = 0.05, epochs = 1, batch_size = 100):\n",
    "    new_weights1, new_bias1 = new_parameters[0]\n",
    "    new_weights2, new_bias2 = new_parameters[1]\n",
    "    new_weights3, new_bias3 = new_parameters[2]\n",
    "    # declare the training data placeholders\n",
    "    # input x - for 28 x 28 pixels = 784\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    # now declare the output data placeholder - 10 digits\n",
    "    y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    # now declare the weights connecting the input to the hidden layer\n",
    "    init_W1 = tf.constant(new_weights1, dtype=tf.float32)\n",
    "    W1 = tf.Variable(init_W1, name='W1', trainable = False)\n",
    "    init_b1 = tf.constant(new_bias1, dtype=tf.float32)\n",
    "    b1 = tf.Variable(init_b1, name='b1', trainable = False)\n",
    "    # the weights connecting the hidden layer to the other hidden layer\n",
    "    init_W2 = tf.constant(new_weights2, dtype=tf.float32)\n",
    "    W2 = tf.Variable(init_W2, name='W2', trainable = False)\n",
    "    init_b2 = tf.constant(new_bias2, dtype=tf.float32)\n",
    "    b2 = tf.Variable(init_b2, name='b2', trainable = False)\n",
    "    # and the weights connecting the hidden layer to the output layer\n",
    "    init_W3 = tf.constant(new_weights3, dtype=tf.float32)\n",
    "    W3 = tf.Variable(init_W3, name='W3', trainable = False)\n",
    "    init_b3 = tf.constant(new_bias3, dtype=tf.float32)\n",
    "    b3 = tf.Variable(init_b3, name='b3')\n",
    "\n",
    "    # calculate the output of the hidden layers\n",
    "    hidden_out_1 = tf.add(tf.matmul(x, W1), b1)\n",
    "    hidden_out_1 = tf.nn.relu(hidden_out_1)\n",
    "    hidden_out_2 = tf.nn.relu(tf.add(tf.matmul(hidden_out_1, W2), b2))\n",
    "    # now calculate the hidden layer output - in this case, let's use a softmax activated\n",
    "    # output layer\n",
    "    y_ = tf.nn.softmax(tf.add(tf.matmul(hidden_out_2, W3), b3))\n",
    "\n",
    "\n",
    "    #Compute cross entropy\n",
    "    y_clipped = tf.clip_by_value(y_, 1e-10, 0.9999999) # Being sure we don't have ln(0)\n",
    "    cross_entropy = -tf.reduce_mean(tf.reduce_sum(y * tf.log(y_clipped)\n",
    "                             + (1 - y) * tf.log(1 - y_clipped), axis=1))\n",
    "\n",
    "    # add an optimiser\n",
    "    optimiser = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "\n",
    "    # finally setup the initialisation operator\n",
    "    init_op = tf.global_variables_initializer()\n",
    "\n",
    "    # define an accuracy assessment operation\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        acc = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "    return acc\n",
    "\n",
    "#new_nets(new_parameters2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put everything in one function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dbf9fd4a3949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mWeights1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mWeights2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mWeights3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msampling_fea\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parameters' is not defined"
     ]
    }
   ],
   "source": [
    "Weights1, bias1 = parameters[0]\n",
    "Weights2, bias2 = parameters[1]\n",
    "Weights3, bias3 = parameters[2]\n",
    "\n",
    "def sampling_fea(k_f, kernel):\n",
    "    \n",
    "    print(\"begin kdpp over features\")\n",
    "    kddpf = kDPP(mnist.train.images[:3300], kernel)\n",
    "    act_f, idx_f = kddpf.sample(k_f)\n",
    "    print(\"end kdpp over features\")\n",
    "    \n",
    "    return idx_f\n",
    "\n",
    "def results(idx_f, k_1, k_2, kernel, Weights1 = Weights1,  Weights2 = Weights2, Weights3 = Weights3, bias1 = bias1, bias2 = bias2, bias3 = bias3):\n",
    "    \n",
    "    print(\"begin pruning for layer 1\")\n",
    "    layer = 1\n",
    "    act_layer1, act_layer2, act_layer3 = rebuild_act_labels_im(Weights1,  Weights2, Weights3, bias1, bias2, bias3, idx_f)\n",
    "    kdpp1 = kDPP(act_layer1.T, kernel)\n",
    "    act_idx1, idx1 = kdpp1.sample(k_1)\n",
    "    new_parameters1, drop_idx, drop_weights = prune_neurons(idx1, layer, parameters)\n",
    "    print(\"end pruning for layer 1\")\n",
    "    \n",
    "    print(\"begin reweighting for layer 1\")\n",
    "    activations = np.array([act_idx1, act_layer1.T, act_layer2.T, act_layer3.T])\n",
    "    new_parameters1 = reweight(layer, activations, new_parameters1, idx1, drop_idx, drop_weights)\n",
    "    print(\"end reweighting for layer 1\")\n",
    "    \n",
    "#     print(\"begin pruning for layer 2\")\n",
    "#     layer = 2\n",
    "#     kdpp2 = kDPP(act_layer2.T, kernel)\n",
    "#     act_idx2, idx2 = kdpp2.sample(k_2)\n",
    "#     new_parameters2, drop_idx, drop_weights = prune_neurons(idx2, layer, new_parameters1)\n",
    "#     print(\"end pruning for layer 2\")\n",
    "    \n",
    "#     print(\"begin reweighting for layer 2\")\n",
    "#     activations = np.array([act_idx2, act_layer1.T, act_layer2.T, act_layer3.T])\n",
    "#     new_parameters2 = reweight(layer, activations, new_parameters2, idx2, drop_idx, drop_weights)\n",
    "#     print(\"end reweighting for layer 2\")\n",
    "    \n",
    "    return new_nets(new_parameters1) #new_parameters2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin kdpp over features\n",
      "end kdpp over features\n"
     ]
    }
   ],
   "source": [
    "idx_f = sampling_fea(1100, kernel_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k 100 gain 0.1 len 0.1\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 100 gain 0.1 len 1\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 100 gain 0.1 len 10\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 100 gain 0.1 len 100\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 100 gain 1 len 0.1\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 100 gain 1 len 1\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 100 gain 1 len 10\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 100 gain 1 len 100\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 100 gain 10 len 0.1\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 100 gain 10 len 1\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 100 gain 10 len 10\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 100 gain 10 len 100\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 100 gain 100 len 0.1\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 100 gain 100 len 1\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 100 gain 100 len 10\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 100 gain 100 len 100\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 150 gain 0.1 len 0.1\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 150 gain 0.1 len 1\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 150 gain 0.1 len 10\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 150 gain 0.1 len 100\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 150 gain 1 len 0.1\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 150 gain 1 len 1\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 150 gain 1 len 10\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 150 gain 1 len 100\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 150 gain 10 len 0.1\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 150 gain 10 len 1\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 150 gain 10 len 10\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 150 gain 10 len 100\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 150 gain 100 len 0.1\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 150 gain 100 len 1\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 150 gain 100 len 10\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 150 gain 100 len 100\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 200 gain 0.1 len 0.1\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 2\n",
      "k 200 gain 0.1 len 1\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 2\n",
      "k 200 gain 0.1 len 10\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 2\n",
      "k 200 gain 0.1 len 100\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 2\n",
      "k 200 gain 1 len 0.1\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 2\n",
      "k 200 gain 1 len 1\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 2\n",
      "k 200 gain 1 len 10\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 2\n",
      "k 200 gain 1 len 100\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 2\n",
      "k 200 gain 10 len 0.1\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 2\n",
      "k 200 gain 10 len 1\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 2\n",
      "k 200 gain 10 len 10\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 2\n",
      "k 200 gain 10 len 100\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 2\n",
      "k 200 gain 100 len 0.1\n",
      "begin pruning for layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 2\n",
      "k 200 gain 100 len 1\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: overflow encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:103: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  e[n,l]=e[n-1,l] + l_eig[n-1]*e[n-1,l-1]\n",
      "/Users/jean-jacquessimeoni/Desktop/kdpp.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if u < l_eig[n]*e[n][l-1]/e[n+1][l]:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9d95d7d3e91a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"k\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gain\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"len\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_se\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mresults_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-cac97c92cee6>\u001b[0m in \u001b[0;36mresults\u001b[0;34m(idx_f, k_1, k_2, kernel, Weights1, Weights2, Weights3, bias1, bias2, bias3)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"begin reweighting for layer 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mact_idx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_layer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_layer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_layer3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mnew_parameters1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreweight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_parameters1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"end reweighting for layer 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-17740f63be95>\u001b[0m in \u001b[0;36mreweight\u001b[0;34m(layer, activations, new_parameters, idx, drop_idx, drop_weights)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0malpha_results\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproj1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0mallvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m     \u001b[0mwarnflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m     \u001b[0mgnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvecnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgfk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgnorm\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mgtol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0mpk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgfk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mvecnorm\u001b[0;34m(x, ord)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvecnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mord\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mInf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mord\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mInf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2332\u001b[0m     \"\"\"\n\u001b[1;32m   2333\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out, keepdims=keepdims,\n\u001b[0;32m-> 2334\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "results_=[]\n",
    "for k in [100, 150, 200, 250, 300, 350]:\n",
    "    for coef0 in \n",
    "        for gamma in [0.1, 1, 10, 100]:\n",
    "            for degree in [0.1, 1, 10, 100]:\n",
    "                kernel_pol = lambda X, Y: polynomial_kernel(X, Y, \n",
    "                                                            degree=degree, gamma=gamma,\n",
    "                                                            coef0=coef0)\n",
    "                print(\"degree\", degree, \"gamma\", gamma, \"coef0\", coef0)\n",
    "                acc = results(idx_f, k, k, kernel_se)\n",
    "                results_.append((k, gain, len_, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(results_,columns=[\"k\", \"coef0\", \"gamma\", \"degree\", \"accuracy\"])\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9504</td>\n",
       "      <td>0.9505</td>\n",
       "      <td>0.9457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.9628</td>\n",
       "      <td>0.9615</td>\n",
       "      <td>0.9427</td>\n",
       "      <td>0.9550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.9587</td>\n",
       "      <td>0.9509</td>\n",
       "      <td>0.9477</td>\n",
       "      <td>0.9466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>0.9548</td>\n",
       "      <td>0.9420</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy                        \n",
       "length    0.1     1.0     10.0    100.0\n",
       "gain                                   \n",
       "0.1      0.9500  0.9504  0.9505  0.9457\n",
       "1.0      0.9628  0.9615  0.9427  0.9550\n",
       "10.0     0.9587  0.9509  0.9477  0.9466\n",
       "100.0    0.9548  0.9420  0.9500  0.9480"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_100 = data[data['k'] == 100]\n",
    "del data_100['k']\n",
    "pivot_100=data_100.pivot('gain',  'length')\n",
    "pivot_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gain        1.0000\n",
       "length      0.1000\n",
       "accuracy    0.9628\n",
       "Name: 4, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx=data_100[\"accuracy\"].argmax()\n",
    "best=data_100.iloc[best_idx]\n",
    "gain=best[\"gain\"]\n",
    "length=best[\"length\"]\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.9727</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>0.9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.9712</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.9657</td>\n",
       "      <td>0.9636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>0.9694</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>0.9636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy                        \n",
       "length    0.1     1.0     10.0    100.0\n",
       "gain                                   \n",
       "0.1      0.9681  0.9693  0.9686  0.9657\n",
       "1.0      0.9727  0.9656  0.9644  0.9665\n",
       "10.0     0.9712  0.9622  0.9657  0.9636\n",
       "100.0    0.9694  0.9662  0.9666  0.9636"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_150 = data[data['k'] == 150]\n",
    "del data_150['k']\n",
    "pivot_150=data_150.pivot('gain',  'length')\n",
    "pivot_150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gain        1.0000\n",
       "length      0.1000\n",
       "accuracy    0.9727\n",
       "Name: 20, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx=data_150[\"accuracy\"].argmax()\n",
    "best=data_150.loc[best_idx]\n",
    "gain=best[\"gain\"]\n",
    "length=best[\"length\"]\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.9714</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>0.9732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.9741</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.9711</td>\n",
       "      <td>0.9696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.9754</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.9708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>0.9754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy                        \n",
       "length    0.1     1.0     10.0    100.0\n",
       "gain                                   \n",
       "0.1      0.9756  0.9714  0.9735  0.9732\n",
       "1.0      0.9741  0.9755  0.9711  0.9696\n",
       "10.0     0.9754  0.9704  0.9700  0.9708\n",
       "100.0    0.9754     NaN     NaN     NaN"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_200 = data[data['k'] == 200]\n",
    "del data_200['k']\n",
    "pivot_200=data_200.pivot('gain',  'length')\n",
    "pivot_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gain        0.1000\n",
       "length      0.1000\n",
       "accuracy    0.9756\n",
       "Name: 32, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx=data_200[\"accuracy\"].argmax()\n",
    "best=data_200.loc[best_idx]\n",
    "gain=best[\"gain\"]\n",
    "length=best[\"length\"]\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.9776</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>0.9763</td>\n",
       "      <td>0.9761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.9778</td>\n",
       "      <td>0.9776</td>\n",
       "      <td>0.9746</td>\n",
       "      <td>0.9751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy                        \n",
       "length    0.1     1.0     10.0    100.0\n",
       "gain                                   \n",
       "1.0      0.9776  0.9793  0.9763  0.9761\n",
       "10.0     0.9778  0.9776  0.9746  0.9751"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_250 = data[data['k'] == 250]\n",
    "del data_250['k']\n",
    "pivot_250=data_250.pivot('gain',  'length')\n",
    "pivot_250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gain        1.0000\n",
       "length      1.0000\n",
       "accuracy    0.9793\n",
       "Name: 46, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx=data_250[\"accuracy\"].argmax()\n",
    "best=data_250.loc[best_idx]\n",
    "gain=best[\"gain\"]\n",
    "length=best[\"length\"]\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gain</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.9787</td>\n",
       "      <td>0.9794</td>\n",
       "      <td>0.9777</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy                        \n",
       "length    0.1     1.0     10.0    100.0\n",
       "gain                                   \n",
       "1.0      0.9787  0.9794  0.9777     NaN\n",
       "10.0        NaN     NaN     NaN  0.9774"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_300 = data[data['k'] == 300]\n",
    "del data_300['k']\n",
    "pivot_300=data_300.pivot('gain',  'length')\n",
    "pivot_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gain        1.0000\n",
       "length      1.0000\n",
       "accuracy    0.9794\n",
       "Name: 54, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx=data_300[\"accuracy\"].argmax()\n",
    "best=data_300.loc[best_idx]\n",
    "gain=best[\"gain\"]\n",
    "length=best[\"length\"]\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_350 = data[data['k'] == 350]\n",
    "del data_350['k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gain        10.0000\n",
       "length       0.1000\n",
       "accuracy     0.9802\n",
       "Name: 61, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx=data_350[\"accuracy\"].argmax()\n",
    "best=data_350.loc[best_idx]\n",
    "gain=best[\"gain\"]\n",
    "length=best[\"length\"]\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_f = np.arange(1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k 100\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "step 350\n",
      "end reweighting for layer 2\n",
      "k 150\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "step 300\n",
      "end reweighting for layer 2\n",
      "k 200\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "step 250\n",
      "end reweighting for layer 2\n",
      "k 250\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "step 200\n",
      "end reweighting for layer 2\n",
      "k 300\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "step 150\n",
      "end reweighting for layer 2\n",
      "k 350\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "step 100\n",
      "end reweighting for layer 2\n",
      "k 400\n",
      "begin pruning for layer 1\n",
      "end pruning for layer 1\n",
      "begin reweighting for layer 1\n",
      "step 0\n",
      "step 50\n",
      "end reweighting for layer 1\n",
      "begin pruning for layer 2\n",
      "end pruning for layer 2\n",
      "begin reweighting for layer 2\n",
      "step 0\n",
      "step 50\n",
      "end reweighting for layer 2\n"
     ]
    }
   ],
   "source": [
    "results_a=[]\n",
    "for k in [100, 150, 200, 250, 300, 350, 400]:\n",
    "    print(\"k\", k)\n",
    "    acc = results(idx_f, k, k, angular)\n",
    "    results_a.append((k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.9307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>0.9557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>0.9668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250</td>\n",
       "      <td>0.9721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>0.9755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>350</td>\n",
       "      <td>0.9757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>400</td>\n",
       "      <td>0.9780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k  accuracy\n",
       "0  100    0.9307\n",
       "1  150    0.9557\n",
       "2  200    0.9668\n",
       "3  250    0.9721\n",
       "4  300    0.9755\n",
       "5  350    0.9757\n",
       "6  400    0.9780"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_a = pd.DataFrame(results_a, columns=[\"k\",\"accuracy\"])\n",
    "data_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Best_Gauss = np.array([0.9628, 0.9727, 0.9756, 0.9793, 0.9794, 0.9802, 0.9802])\n",
    "Best_ang = np.array(data_a[\"accuracy\"])\n",
    "Best = np.array([0.9802 for i in range(7)])\n",
    "x = np.array([100, 150, 200, 250, 300, 350, 400])\n",
    "plt.plot(x, Best_Gauss, color = 'r', label = \"Gaussian Kernel\")\n",
    "plt.plot(x, Best_ang, color = 'y', label = \"Angular Kernel\")\n",
    "plt.xlabel(\"Number of Neurons per layer\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(x, Best, label = \"target\")\n",
    "plt.legend()\n",
    "plt.title(\"Network Compression Results\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Best_Gauss = 100 * np.array([(0.9802 - 0.9628)/0.9628, (0.9802 - 0.9727)/ 0.9727, (0.9802 - 0.9756)/0.9756\n",
    "                       , (0.9802 - 0.9793)/0.9793, (0.9802 - 0.9794)/0.9794, 0, 0])\n",
    "Best_ang = 100 * np.array((0.9802 - data_a[\"accuracy\"])/data_a[\"accuracy\"])\n",
    "x = np.array([100, 150, 200, 250, 300, 350, 400])\n",
    "plt.plot(x, Best_Gauss, color = 'r', label = \"Gaussian Kernel\")\n",
    "plt.plot(x, Best_ang, color = 'y', label = \"Angular Kernel\")\n",
    "plt.xlabel(\"Number of Neurons per layer\")\n",
    "plt.ylabel(\"Accuracy Error in %\")\n",
    "plt.legend()\n",
    "plt.title(\"Network Compression Results\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
